{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57c865aa-ebd5-4944-a381-ca3a5f49c6ed",
   "metadata": {},
   "source": [
    "#### Create and Train a RNN \n",
    "to predict the value of the voltage rise on the next period\n",
    "\n",
    "Prediction is done in [VoltageRiseNum_Pred](VoltageRiseNum_Pred.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f9d2d-b714-45fd-945a-7569c7a6c44f",
   "metadata": {},
   "source": [
    "We consider \n",
    "\n",
    "\\begin{equation}\n",
    "Z(k) = \\begin{bmatrix} X(k-1)\\\\ \\vdots \\\\ X(k-6)\\ \\end{bmatrix}, \\;\\; \\text{where} \\; \\; \n",
    "X(k-i) = \\begin{bmatrix} P_{load}(k-i) \\\\ P_{BT}(k-i) \\\\ P0013(k-i) \\\\ P0018(k-i) \\\\ P0100(k-i)\\\\ max\\_vm\\_pu(k-i) \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "to predict \n",
    "\n",
    "\\begin{equation} Pred = \\begin{bmatrix} P_{load}(k)\\\\  max\\_vm\\_pu(k) \\end{bmatrix} \\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "I am predicting column [0,5] i.e ['Cons','Voltage_rise'] even though the only column of interest is 5. \n",
    "This is because the RNN does not learn well when one is predicting on a unique feature. \n",
    "Column 5 is the one considered among all because it has the smoothest curve within the backward \n",
    "looking window considered hence yield the best accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff44841-10f2-4728-baba-ae19c2c94033",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269c2ae-4edb-4edc-b9e6-5e8fc8a519e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Import modules to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d03799f-9341-49e9-aa88-949421832c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules \n",
    "import pandas as pd\n",
    "import pandapower as pp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm # Profiling \n",
    "import seaborn as sbn\n",
    "import pickle, sys, importlib,  time\n",
    "import os\n",
    "from pickle import load\n",
    "import tensorflow as tf\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d347d27-fe03-477d-99fa-7aacb227bdc3",
   "metadata": {},
   "source": [
    "#### Import Module for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43792d1d-65aa-49b5-9bbd-12f6a4b4cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pakages forML\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f0de16-0ff9-4e01-b390-588b05658960",
   "metadata": {},
   "source": [
    "#### Import my own modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eff66d5f-be91-4067-8bf6-20fd790ee8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psutil\n",
    "function_folder = 'py_files/' \n",
    "# Add function folder to path if it is not already\n",
    "if function_folder not in sys.path: sys.path.append(function_folder)\n",
    "\n",
    "import oriFunctions as oriFc\n",
    "from oriFunctions import network_folder, excel_folder, py_folder, Î”t, attr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37aefb25-d718-42a7-af41-1aa8fb9467d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Networks\n",
    "net_civaux=pp.from_pickle(f'{network_folder}CIVAUX.p')\n",
    "net_stlaurent=pp.from_pickle(f'{network_folder}ST LAURENT.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4102c066-dcdb-45b7-9b16-0a0c17e3e339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load files\n",
    "file_p_inj_0013 = 'Prod_HTA/PROD_Bis/P0013/PROD-BATISOLAIRE 6-CIVAUX - Actif injecte (P-).csv'\n",
    "file_p_inj_0018 = 'Prod_HTA/PROD_Bis/P0018/PROD-SUN POITOU 2516 (Z.I de la Pitage)-LHOMMAIZE - Actif injecte (P-).csv'\n",
    "\n",
    "\n",
    "# The  commissioning of the Prod P0100 is recent (2022). I therefore use the data of the closer energy \n",
    "# producer that is P0058  and consider it as that of Prod P0100 \n",
    "file_p_inj_0100 = 'Prod_HTA/PROD_Bis/PROD-SERGIES 2204 (LA ROCHE A CORNUCHON)-PINDRAY - Actif P-.csv'\n",
    "\n",
    "file_prod_bt_total = 'PROD_BTSUP36_SAINT LAURENT.csv'\n",
    "file_cons_total = 'CONSO_POSTE_SAINT LAURENT.csv'\n",
    "\n",
    "\n",
    "# Get files data \n",
    "p_mw_0013 = oriFc.readAndReshape_excelFile(file_p_inj_0013 ,excel_folder, )\n",
    "p_mw_0018 = oriFc.readAndReshape_excelFile(file_p_inj_0018 ,excel_folder,)\n",
    "p_mw_0100 = oriFc.readAndReshape_excelFile(file_p_inj_0100 ,excel_folder,)\n",
    "\n",
    "\n",
    "p_mw_prod_bt_total = oriFc.readAndReshape_excelFile(file_prod_bt_total, excel_folder)\n",
    "p_mw_cons_total = oriFc.readAndReshape_excelFile(file_cons_total, excel_folder)\n",
    "\n",
    "# Create dict for all HT producers\n",
    "dict_prod_hv = {'P0013': p_mw_0013[:len(p_mw_0100)], \n",
    "                'P0018': p_mw_0018[:len(p_mw_0100)],\n",
    "                'P0100': p_mw_0100[:len(p_mw_0100)]\n",
    "               }\n",
    "# Create index to use for dataframe\n",
    "per_index = pd.period_range('01 01 2020', periods=len(p_mw_0100), freq='10T')\n",
    "\n",
    "# Use the create dict to create a dataFrame for Prod P0100\n",
    "df_prodP0100 = pd.DataFrame(p_mw_0100, index=per_index)\n",
    "\n",
    "# Use the create dict to create a dataFrame for all HT producers\n",
    "df_prodHT = pd.DataFrame(dict_prod_hv, index=per_index)\n",
    "\n",
    "# Dataframe prod BT \n",
    "per_index = pd.period_range('01 01 2020', periods=len(p_mw_prod_bt_total), freq='10T')\n",
    "df_prod_bt_total = pd.DataFrame(p_mw_prod_bt_total, index=per_index, columns=['Prod_BT'])\n",
    "\n",
    "\n",
    "# Dataframe Conso BT \n",
    "per_index = pd.period_range('01 01 2020', periods=len(p_mw_cons_total), freq='10T')\n",
    "df_cons_total = pd.DataFrame(p_mw_cons_total, index=per_index, columns=['Cons'])\n",
    "\n",
    "# Data cleaning on Consumption\n",
    "# Replacing wrong data by the mean of surrounding periods\n",
    "# 2020 -------------------------\n",
    "previous_days = df_cons_total[(per_index>='2020 06 11') & (per_index<='2020 06 21 23:50')]\n",
    "following_days = df_cons_total[(per_index>='2020 07 03') & (per_index<='2020 07 13 23:50')]\n",
    "# Put the interpolated data into the dataframe\n",
    "df_cons_total[(per_index>='2020 06 22') & (per_index<='2020 07 02 23:50')] = (np.array(following_days) + \n",
    "                                                                              np.array(previous_days) )/2\n",
    "# 2022 -------------------------\n",
    "previous_days = df_cons_total[(per_index>='2022 02 12') & (per_index<='2022 02 21 23:50')]\n",
    "following_days = df_cons_total[(per_index>='2022 03 03') & (per_index<='2022 03 12 23:50')]\n",
    "# # Put the interpolated data into the dataframe\n",
    "df_cons_total[(per_index>='2022 02 21') & (per_index<='2022 03 02 23:50')] = (np.array(following_days) + \n",
    "                                                                              np.array(previous_days) )/2\n",
    "# Dataframe PROD HT\n",
    "# Replacing missing data by the mean of surrondings periods\n",
    "# Extract previous and following days \n",
    "per_index = df_prodHT.index\n",
    "previous_days = df_prodHT.loc[(per_index>='2020 06 11') & (per_index<='2020 06 21 23:50'),['P0013','P0018']]\n",
    "following_days = df_prodHT.loc[(per_index>='2020 07 03') & (per_index<='2020 07 13 23:50'),['P0013','P0018']]\n",
    "\n",
    "# Put the interpolated data into the dataframe\n",
    "df_prodHT.loc[(per_index>='2020 06 22') & (per_index<='2020 07 02 23:50'), ['P0013','P0018']] = (np.array(following_days) +\n",
    "                                                                                                 np.array(previous_days) ) /2\n",
    "\n",
    "\n",
    "# Get total Power of BT producers\n",
    "# Bt producers are indexed by the name None\n",
    "max_p_mw_total_prodBT = net_civaux.sgen.max_p_mw[net_civaux.sgen.name.isna()].sum()\n",
    "\n",
    "# # Get total power of load in the network\n",
    "max_p_mw_total_load = net_civaux.load.max_p_mw.sum()\n",
    "\n",
    "# Select relevant data up to 2022 06 01\n",
    "df_prodHT = df_prodHT[df_prodHT.index<='2022 06 01 23:50']\n",
    "df_prod_bt_total = df_prod_bt_total[df_prod_bt_total.index<='2022 06 01 23:50']\n",
    "df_cons_total = df_cons_total[df_cons_total.index<='2022 06 01 23:50']\n",
    "\n",
    "\n",
    "# Extract only dailight period i.e. from 07am to 7PM\n",
    "# The daylight period is considered to be defined betwenn 07am and 7Pm excluded. \n",
    "h_start_end = ('06:50','18:50') # for the persistance model, the previous period i.e. 06:50 \n",
    "                                # is needed to compute the first instant i.e. 07:00\n",
    "per_index = df_prodHT.index\n",
    "per_daylight = ( pd.Series(index=per_index.to_timestamp(), dtype=object).between_time(*h_start_end) ).index.to_period('10T')\n",
    "day_tot_per = len(per_daylight[(per_daylight.year==2020)&(per_daylight.month==1)&(per_daylight.day==1)])\n",
    "\n",
    "\n",
    "# Put all the data in a unique dataframe\n",
    "df_data = pd.concat([df_cons_total, df_prod_bt_total, df_prodHT], axis=1).loc[per_daylight]\n",
    "\n",
    "# # Extract only the relavant testing set since the training set covers the first part of the data\n",
    "df_final = df_data[df_data.index<'2021 06 01']\n",
    "per_index = df_final.index\n",
    "per_index2 = ( pd.Series(index=per_index.to_timestamp(), dtype=object\n",
    "                           ).between_time('07:00','18:50') ).index.to_period('10T')\n",
    "\n",
    "\n",
    "vm_mu_max, vm_mu_min = 1.0250, 0.95  # Choosen \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34489214-f7ac-4c72-8928-539e9ac10c97",
   "metadata": {},
   "source": [
    "#### Import the voltage rise from [Voltage_rise](VoltageRiseBinary.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "540395a2-3954-48d9-add1-e89efde8afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the voltage rise from \n",
    "bin_volt_rise = joblib.load('pickle_files/simulationResults/Binary_Voltage_Rise.pkl')\n",
    "df_final['Volt_Rise_bin'] = bin_volt_rise['Volt_Rise_Bin']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f527d0e2-45a6-4c67-98c7-95df0b3e3333",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set variables For numerical voltage rise prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e88b9ed-272d-408a-9e9a-790996599e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract only the relavant testing set since the training set covers the first part of the data\n",
    "df_final = df_data[df_data.index<'2021 06 01']\n",
    "per_index = df_final.index\n",
    "per_index2 = ( pd.Series(index=per_index.to_timestamp(), dtype=object\n",
    "                        ).between_time('07:00','18:50') ).index.to_period('10T')\n",
    "df_final['Volt_Rise_num'] = bin_volt_rise['known']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ee5698c-493b-4d89-b334-e87277611117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cons</th>\n",
       "      <th>Prod_BT</th>\n",
       "      <th>P0013</th>\n",
       "      <th>P0018</th>\n",
       "      <th>P0100</th>\n",
       "      <th>Volt_Rise_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 06:50</th>\n",
       "      <td>11.489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 07:00</th>\n",
       "      <td>11.795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 07:10</th>\n",
       "      <td>11.704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 07:20</th>\n",
       "      <td>11.583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 07:30</th>\n",
       "      <td>11.611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Cons  Prod_BT  P0013  P0018  P0100  Volt_Rise_num\n",
       "2020-01-01 06:50  11.489      0.0    0.0    0.0    0.0            1.0\n",
       "2020-01-01 07:00  11.795      0.0    0.0    0.0    0.0            1.0\n",
       "2020-01-01 07:10  11.704      0.0    0.0    0.0    0.0            1.0\n",
       "2020-01-01 07:20  11.583      0.0    0.0    0.0    0.0            1.0\n",
       "2020-01-01 07:30  11.611      0.0    0.0    0.0    0.0            1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae6cc885-54aa-457f-a8d1-529977f2f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate training and testing set \n",
    "df_train = df_final[df_final.index<'2021 06 01']\n",
    "\n",
    "\n",
    "# I'm using all the dataset to train the RNN to improve the performance since ive already\n",
    "# tried with the testing set and get an accuraccy of 94%\n",
    "# # Separate training and testing set \n",
    "# df_train = df_final[df_final.index<'2021 06 01']\n",
    "\n",
    "# Define scaler\n",
    "numerical_scaler2 = MinMaxScaler()\n",
    "numerical_scaler_out = MinMaxScaler()\n",
    "\n",
    "numerical_scaler2.fit(df_train);\n",
    "numerical_scaler_out.fit(df_train.iloc[:,[0,5]])\n",
    "\n",
    "train_scaled = numerical_scaler2.transform(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2986b64-ec01-44e6-b0be-707b852f4f0f",
   "metadata": {},
   "source": [
    "##### Define Timeseries  generators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d6a0171-7611-4036-99b5-d39a2cdfde01",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_length = 6 # 1 hour\n",
    "\n",
    "batchSize = 24*7*2; #  (gen_length//6)  To convert in hour *24 hour * 7 days\n",
    "# I am predicting column [0,5] i.e ['Cons','Voltage_rise'] even though the only collumn of interest is 5. \n",
    "# This is because the RNN does not learn well when one is predicting on a unique feature. \n",
    "# Column 5 is the one considered among all because it has the smoothest curve within the backward \n",
    "# looking window considered hence yield the best accuracy\n",
    "train_generator = TimeseriesGenerator(train_scaled, train_scaled[:,[0,5]], \n",
    "                                      length = gen_length, \n",
    "                                      batch_size= batchSize )\n",
    "\n",
    "# n_features = train_generator[0][0][0].shape[1]  # Define total number of features\n",
    "n_features_inputs = 6  # Define total number of features in inputs \n",
    "n_features_outputs = 2  # Define total number of features to predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed7b8c3-6464-4dbb-952f-dd58a23b7902",
   "metadata": {},
   "source": [
    "#### Define RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f711328-72c5-4f42-ac42-291a4375aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vRise_RNN = Sequential()\n",
    "\n",
    "num_vRise_RNN.add( LSTM(units=128, activation='relu', input_shape=(gen_length,n_features_inputs)) )\n",
    "# num_vRise_RNN.add( LSTM(units=128, activation='relu' ) )\n",
    "num_vRise_RNN.add(Dense(units=n_features_outputs, activation='relu'))\n",
    "\n",
    "num_vRise_RNN.compile(optimizer='adam', loss='mse', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06d457a-5100-4b69-a9f3-f26c85bfc7f8",
   "metadata": {},
   "source": [
    "##### Define early stopping mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe38775c-7f7c-4a31-8d45-c7997e4305be",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor= 'loss',patience=20, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da22a83-cfaa-407a-86ee-4f0651431515",
   "metadata": {},
   "source": [
    "#### Train RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d954d99-5447-4880-b391-04a0d15f1a35",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - 2s 10ms/step - loss: 0.0173\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0037\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0026\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0022\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0020\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0020\n",
      "Epoch 7/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0019\n",
      "Epoch 8/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0019\n",
      "Epoch 9/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0019\n",
      "Epoch 10/100\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0018\n",
      "Epoch 11/100\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0017\n",
      "Epoch 12/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0018\n",
      "Epoch 13/100\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0017\n",
      "Epoch 14/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0018\n",
      "Epoch 15/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0018\n",
      "Epoch 16/100\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0017\n",
      "Epoch 17/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0017\n",
      "Epoch 18/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0017\n",
      "Epoch 19/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0017\n",
      "Epoch 20/100\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0017\n",
      "Epoch 21/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0016\n",
      "Epoch 22/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0017\n",
      "Epoch 23/100\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0016\n",
      "Epoch 24/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0016\n",
      "Epoch 25/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 26/100\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0016\n",
      "Epoch 27/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 28/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 29/100\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0016\n",
      "Epoch 30/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0017\n",
      "Epoch 31/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 32/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 33/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0016\n",
      "Epoch 34/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0016\n",
      "Epoch 35/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0016\n",
      "Epoch 36/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 37/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 38/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0017\n",
      "Epoch 39/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0017\n",
      "Epoch 40/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0017\n",
      "Epoch 41/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 42/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0016\n",
      "Epoch 43/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0016\n",
      "Epoch 44/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0016\n",
      "Epoch 45/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0016\n",
      "Epoch 46/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0016\n",
      "Epoch 47/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 48/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 49/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 50/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 51/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0016\n",
      "Epoch 52/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0016\n",
      "Epoch 53/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0015\n",
      "Epoch 54/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0015\n",
      "Epoch 55/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0016\n",
      "Epoch 56/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0015\n",
      "Epoch 57/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0016\n",
      "Epoch 58/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0016\n",
      "Epoch 59/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015\n",
      "Epoch 60/100\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0016\n",
      "Epoch 61/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0015\n",
      "Epoch 62/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015\n",
      "Epoch 63/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 64/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 65/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0015\n",
      "Epoch 66/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0016\n",
      "Epoch 67/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0015\n",
      "Epoch 68/100\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0015\n",
      "Epoch 69/100\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0015\n",
      "Epoch 70/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0015\n",
      "Epoch 71/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015\n",
      "Epoch 72/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015\n",
      "Epoch 73/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0016\n",
      "Epoch 74/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0015\n",
      "Epoch 75/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015\n",
      "Epoch 76/100\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0015\n",
      "Epoch 77/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0015\n",
      "Epoch 78/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0015\n",
      "Epoch 79/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0015\n",
      "Epoch 80/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0015\n",
      "Epoch 81/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015\n",
      "Epoch 82/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0015\n",
      "Epoch 83/100\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.0015\n",
      "Epoch 84/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0015\n",
      "Epoch 85/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0015\n",
      "Epoch 86/100\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0015\n",
      "Epoch 87/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0015\n",
      "Epoch 88/100\n",
      "113/113 [==============================] - 2s 15ms/step - loss: 0.0015\n",
      "Epoch 89/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0015\n",
      "Epoch 90/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0015\n",
      "Epoch 91/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0015\n",
      "Epoch 92/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0015\n",
      "Epoch 93/100\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0015\n",
      "Epoch 94/100\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0015\n",
      "Epoch 95/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0015\n",
      "Epoch 96/100\n",
      "113/113 [==============================] - 1s 13ms/step - loss: 0.0015\n",
      "Epoch 97/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0015\n",
      "Epoch 98/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0015\n",
      "Epoch 99/100\n",
      "113/113 [==============================] - 2s 14ms/step - loss: 0.0015\n",
      "Epoch 100/100\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 0.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f2b08943a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_vRise_RNN.fit(train_generator, \n",
    "                  epochs=100, \n",
    "                  callbacks=[early_stop], \n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f33202dc-3cb1-4199-a3f1-fff3469c0355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pickle_files/RNN/StLaurent_num_vRise_model\\assets\n"
     ]
    }
   ],
   "source": [
    "num_vRise_RNN.save('pickle_files/RNN/StLaurent_num_vRise_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de3c3576-c925-4c72-bc2d-b9344453dd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pickle_files/RNN/StLaurent_num_vRise_scaler.plk']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(numerical_scaler_out,'pickle_files/RNN/StLaurent_num_vRise_scalerPred.plk')\n",
    "joblib.dump(numerical_scaler2,'pickle_files/RNN/StLaurent_num_vRise_scaler.plk')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
